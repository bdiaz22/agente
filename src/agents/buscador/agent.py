"""
Agente Buscador - Prototipo 3

Agente con arquitectura ReAct (Reasoning + Acting) para b칰squedas
multi-fuente en bases de datos y filesystem.

PEDAGOG칈A:
- Demuestra loop ReAct con planeaci칩n din치mica
- Muestra function calling autom치tico con register_tools()
- Implementa detecci칩n de loops infinitos
- Fusi칩n de evidencias de m칰ltiples fuentes
"""

from typing import Dict, Any, List, Optional

from src.framework.base_agent import BaseAgent, AgentResponse
from src.framework.model_provider import ModelProvider
from src.tools.sql_query_tool import SQLQueryTool
from src.tools.document_search_tool import ListDocumentsTool, ReadDocumentTool
from src.tools.finish_tool import FinishTool
from src.agents.buscador.prompts import PLAN_SYSTEM_PROMPT, REACT_SYSTEM_PROMPT
from src.agents.buscador.config import MAX_ITERATIONS, MAX_LOOP_REPEATS


class AgenteBuscador(BaseAgent):
    """
    Agente con loop ReAct para b칰squeda multi-fuente.

    Flujo:
    1. PLAN: Genera estrategia de b칰squeda (2-4 pasos)
    2. ACT: Ejecuta siguiente paso usando una tool
    3. OBSERVE: Guarda resultado en historial
    4. DECIDE: 쯊erminar? Replanificar? 쮺ontinuar?
    5. REPEAT hasta finish o max_iterations
    """

    def __init__(
        self,
        model_provider: ModelProvider,
        sql_tool: SQLQueryTool,
        list_docs_tool: ListDocumentsTool,
        read_doc_tool: ReadDocumentTool,
        finish_tool: FinishTool
    ):
        """
        Args:
            model_provider: Proveedor de LLM con function calling
            sql_tool: Tool para consultas SQL
            list_docs_tool: Tool para listar documentos (como ls/tree)
            read_doc_tool: Tool para leer contenido de documentos
            finish_tool: Tool para terminar el loop
        """
        super().__init__(
            name="AgenteBuscador",
            description="B칰squeda multi-fuente con razonamiento ReAct"
        )
        self.model_provider = model_provider
        self.sql_tool = sql_tool
        self.list_docs_tool = list_docs_tool
        self.read_doc_tool = read_doc_tool
        self.finish_tool = finish_tool
        self.max_iterations = MAX_ITERATIONS

        # Registrar tools para function calling autom치tico
        self.model_provider.register_tools(self)

    async def run(
        self,
        query: str,
        context: Optional[Dict[str, Any]] = None
    ) -> AgentResponse:
        """
        Ejecuta b칰squeda con loop ReAct.

        Args:
            query: Consulta del usuario
            context: Contexto adicional (opcional)

        Returns:
            AgentResponse con resultados y metadata del proceso
        """
        observations: List[Dict[str, Any]] = []
        current_plan: Optional[str] = None

        for iteration in range(self.max_iterations):
            # ============================================
            # PASO 1: PLAN (si no hay plan o hay que replanificar)
            # ============================================
            if current_plan is None or self._should_replan(observations):
                current_plan = await self._generate_plan(query, observations)

            # ============================================
            # PASO 2: ACT (el LLM elige y ejecuta una tool)
            # ============================================
            prompt = self._build_action_prompt(query, current_plan, observations)
            result = await self.model_provider.generate(prompt)

            # Si el LLM responde sin usar tool (edge case)
            if isinstance(result, str):
                # Si hay observaciones y el texto no est치 vac칤o, usarlo como respuesta
                if observations and result.strip():
                    return AgentResponse(
                        content=result,
                        metadata={
                            "plan": current_plan,
                            "observations": observations,
                            "iterations": iteration + 1,
                            "finished_by": "text_response"
                        }
                    )
                # Si el texto est치 vac칤o pero tenemos observaciones, generar resumen
                elif observations:
                    return AgentResponse(
                        content=self._build_summary_from_observations(query, observations),
                        metadata={
                            "plan": current_plan,
                            "observations": observations,
                            "iterations": iteration + 1,
                            "finished_by": "auto_summary"
                        }
                    )
                continue

            # ============================================
            # PASO 3: OBSERVE (guardar resultado)
            # ============================================
            observations.append({
                "step": iteration + 1,
                "tool": result["tool_name"],
                "input": result["arguments"],
                "output": result["result"]
            })

            # ============================================
            # PASO 4: DECIDE (쯦erminar? 쯟oop?)
            # ============================================

            # Detectar loop infinito
            if self._detect_loop(observations):
                return AgentResponse(
                    content=self._build_partial_summary(query, observations),
                    metadata={
                        "plan": current_plan,
                        "observations": observations,
                        "iterations": iteration + 1,
                        "error": "loop_detected"
                    }
                )

            # 쯊ermin칩 con finish?
            if result["tool_name"] == "finish":
                return AgentResponse(
                    content=result["result"]["summary"],
                    metadata={
                        "plan": current_plan,
                        "observations": observations,
                        "iterations": iteration + 1,
                        "sources": result["result"].get("sources", []),
                        "confidence": result["result"].get("confidence", "medium")
                    }
                )

        # Max iterations alcanzado
        return self._fallback_response(query, observations, current_plan)

    async def _generate_plan(
        self,
        query: str,
        observations: List[Dict[str, Any]]
    ) -> str:
        """
        Genera un plan de b칰squeda (sin ejecutar tools).

        El prompt indica claramente que solo debe planificar,
        no ejecutar acciones.
        """
        obs_text = self._format_observations(observations)

        prompt = f"""{PLAN_SYSTEM_PROMPT}

Query del usuario: {query}

{obs_text}

Genera un plan con 2-4 pasos concretos. NO ejecutes ninguna acci칩n, solo planifica.

Formato:
1. [Acci칩n espec칤fica usando sql_query o document_search]
2. [Acci칩n espec칤fica]
...
"""
        plan = await self.model_provider.generate(prompt)

        # Si retorna dict (us칩 tool), extraer texto o usar default
        if isinstance(plan, dict):
            return "1. Buscar informaci칩n relevante\n2. Consolidar resultados"

        return plan

    def _build_action_prompt(
        self,
        query: str,
        plan: str,
        observations: List[Dict[str, Any]]
    ) -> str:
        """Construye el prompt para que el LLM ejecute el siguiente paso."""
        obs_text = self._format_observations(observations)

        return f"""{REACT_SYSTEM_PROMPT}

Query del usuario: {query}

Plan actual:
{plan}

{obs_text}

Ejecuta el siguiente paso del plan usando una tool.
Si ya tienes suficiente informaci칩n, usa "finish" para generar la respuesta final.
"""

    def _format_observations(self, observations: List[Dict[str, Any]]) -> str:
        """Formatea el historial de observaciones para el contexto."""
        if not observations:
            return "A칰n no has realizado ninguna acci칩n."

        formatted = "Historial de acciones:\n"
        for obs in observations:
            # Truncar output si es muy largo
            output = obs["output"]
            if isinstance(output, dict):
                output_str = str(output)
                if len(output_str) > 500:
                    output_str = output_str[:500] + "..."
            else:
                output_str = str(output)

            formatted += f"""
Paso {obs['step']}:
- Tool: {obs['tool']}
- Input: {obs['input']}
- Resultado: {output_str}
"""
        return formatted

    def _should_replan(self, observations: List[Dict[str, Any]]) -> bool:
        """Decide si hay que replanificar (resultado vac칤o, error, etc.)"""
        if not observations:
            return False

        last_obs = observations[-1]
        output = last_obs.get("output", {})

        # Replanificar si el 칰ltimo resultado fue error
        if isinstance(output, dict):
            if output.get("error"):
                return True
            # Replanificar si no hubo resultados
            if output.get("count", -1) == 0:
                return True

        return False

    def _detect_loop(
        self,
        observations: List[Dict[str, Any]],
        max_repeats: int = MAX_LOOP_REPEATS
    ) -> bool:
        """
        Detecta si el agente est치 en un loop infinito.

        Args:
            observations: Lista de observaciones
            max_repeats: M치ximo de repeticiones permitidas (default 3)

        Returns:
            True si se detecta loop
        """
        if len(observations) < max_repeats:
            return False

        # Crear firma de cada observaci칩n (tool + args)
        def signature(obs):
            args = obs.get("input", {})
            if isinstance(args, dict):
                return f"{obs['tool']}:{sorted(args.items())}"
            return f"{obs['tool']}:{args}"

        signatures = [signature(obs) for obs in observations]

        # Detectar si la 칰ltima acci칩n se repiti칩 demasiadas veces
        last_sig = signatures[-1]
        repeat_count = signatures.count(last_sig)

        return repeat_count >= max_repeats

    def _build_partial_summary(
        self,
        query: str,
        observations: List[Dict[str, Any]]
    ) -> str:
        """Construye un resumen parcial cuando hay loop o timeout."""
        summary = f"B칰squeda parcial para: {query}\n\n"

        # Recopilar resultados 칰tiles
        results = []
        for obs in observations:
            output = obs.get("output", {})
            if isinstance(output, dict) and not output.get("error"):
                if output.get("count", 0) > 0:
                    results.append(f"- {obs['tool']}: {output.get('count', 0)} resultados")

        if results:
            summary += "Resultados encontrados:\n" + "\n".join(results)
        else:
            summary += "No se encontraron resultados relevantes."

        return summary

    def _build_summary_from_observations(
        self,
        query: str,
        observations: List[Dict[str, Any]]
    ) -> str:
        """Construye un resumen estructurado a partir de las observaciones."""
        summary_parts = [f"Resultados de b칰squeda para: {query}\n"]

        for obs in observations:
            tool = obs.get("tool", "unknown")
            output = obs.get("output", {})

            if isinstance(output, dict):
                if output.get("error"):
                    continue  # Ignorar errores en el resumen

                count = output.get("count", 0)
                if count > 0:
                    if tool == "sql_query":
                        results = output.get("results", [])
                        if results:
                            # Extraer info clave del primer resultado
                            first = results[0]
                            if "nombre" in first:
                                summary_parts.append(f"\n游늶 Datos del afiliado:")
                                nombre = f"{first.get('nombre', '')} {first.get('apellido_paterno', '')}"
                                summary_parts.append(f"  - Nombre: {nombre}")
                                if "estado" in first:
                                    summary_parts.append(f"  - Estado: {first['estado']}")
                                if "saldo_obligatorio" in first:
                                    saldo = first.get('saldo_obligatorio', 0) + first.get('saldo_voluntario', 0)
                                    summary_parts.append(f"  - Saldo total: ${saldo:,.0f}")
                            elif "monto" in first and "periodo" in first:
                                summary_parts.append(f"\n游눯 Aportes encontrados: {count}")
                            elif "afp_origen" in first:
                                summary_parts.append(f"\n游댃 Traspasos encontrados: {count}")
                            else:
                                summary_parts.append(f"\n游늵 {count} registros encontrados en {tool}")

                    elif tool == "document_search":
                        docs = output.get("documents", [])
                        if docs:
                            summary_parts.append(f"\n游늬 Documentos encontrados: {len(docs)}")
                            for doc in docs[:3]:
                                summary_parts.append(f"  - {doc.get('filename', 'unknown')}")

        if len(summary_parts) == 1:
            summary_parts.append("\nNo se encontraron resultados relevantes.")

        return "\n".join(summary_parts)

    def _fallback_response(
        self,
        query: str,
        observations: List[Dict[str, Any]],
        plan: Optional[str]
    ) -> AgentResponse:
        """Respuesta cuando se alcanza max_iterations."""
        summary = self._build_partial_summary(query, observations)
        summary += f"\n\n(B칰squeda terminada por l칤mite de {self.max_iterations} iteraciones)"

        return AgentResponse(
            content=summary,
            metadata={
                "plan": plan,
                "observations": observations,
                "iterations": self.max_iterations,
                "completed": False,
                "error": "max_iterations_reached"
            }
        )
