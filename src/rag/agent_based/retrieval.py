"""
Retrieval orquestado para Agent RAG

Usa el LLM para evaluar relevancia en vez de b√∫squeda vectorial.

VERSION 2.0: Retrieval con √≠ndices JSON
- Fase 1: LLM filtra documentos relevantes leyendo √≠ndices
- Fase 2: LLM filtra secciones relevantes por documento
- Fase 3: Lee solo secciones espec√≠ficas del contenido
"""

import asyncio
import json
import time
from pathlib import Path
from typing import List, Dict, Any, Optional
from .document_reader import DocumentReader
from .chunk_evaluator import ChunkEvaluator


class AgentRetrieval:
    """
    Orquestador del flujo completo de Agent RAG.

    PEDAGOG√çA:
    - DIFERENCIA CON VECTOR RAG:
      * NO usa embeddings
      * NO usa vector store
      * El LLM lee y eval√∫a directamente
    - VENTAJA: Transparencia total (el LLM explica el "por qu√©")
    - DESVENTAJA: M√°s lento y costoso

    CU√ÅNDO USAR:
    - Pocos documentos (<100)
    - Necesitas explicabilidad
    - No quieres infraestructura de vectores
    """

    def __init__(
        self,
        document_reader: DocumentReader,
        chunk_evaluator: ChunkEvaluator
    ):
        """
        Args:
            document_reader: Lector de documentos
            chunk_evaluator: Evaluador con LLM
        """
        self.document_reader = document_reader
        self.chunk_evaluator = chunk_evaluator

    async def retrieve(
        self,
        query: str,
        k: int = 5,
        documents_path: str = "data/documentos"
    ) -> Dict[str, Any]:
        """
        Recupera documentos relevantes usando el LLM como juez.

        PEDAGOG√çA:
        - Flujo diferente a Vector RAG:
          1. Leer TODOS los documentos
          2. Evaluar CADA UNO con el LLM
          3. Rankear por score
          4. Retornar top-k

        OPTIMIZACI√ìN:
        - Evaluaciones en paralelo (asyncio.gather)
        - Sin paralelo, ser√≠a muy lento (N llamadas secuenciales al LLM)

        Args:
            query: Consulta del usuario
            k: N√∫mero de documentos a retornar
            documents_path: Ruta a documentos

        Returns:
            Dict con chunks y reasoning del LLM
        """
        # 1. Leer todos los documentos
        documents = await self.document_reader.read_all_documents(documents_path)

        # 2. Evaluar relevancia de cada documento EN PARALELO
        # Esto reduce latencia de N*time a ~time
        evaluation_tasks = [
            self.chunk_evaluator.evaluate_relevance(query, doc)
            for doc in documents
        ]
        evaluations = await asyncio.gather(*evaluation_tasks)

        # 3. Combinar documentos con evaluaciones
        scored_docs = []
        for doc, evaluation in zip(documents, evaluations):
            scored_docs.append({
                "content": doc["content"],
                "metadata": doc["metadata"],
                "score": evaluation["relevance_score"],
                "reasoning": evaluation["reasoning"],
                "relevant_sections": evaluation["relevant_sections"]
            })

        # 4. Rankear por score descendente
        scored_docs.sort(key=lambda x: x["score"], reverse=True)

        # 5. Tomar top-k
        top_docs = scored_docs[:k]

        # 6. Formatear con citas diferenciadas de Vector RAG
        formatted_chunks = []
        for doc in top_docs:
            citation = self._format_citation(doc["metadata"], doc["score"])

            formatted_chunks.append({
                "content": doc["content"],
                "metadata": doc["metadata"],
                "score": doc["score"],
                "reasoning": doc["reasoning"],  # √öNICO DE AGENT RAG
                "citation": citation
            })

        return {
            "chunks": formatted_chunks,
            "method": "agent_rag"  # Identificador del m√©todo
        }

    def _format_citation(self, metadata: Dict[str, Any], score: float) -> str:
        """
        Formatea cita distinguible de Vector RAG.

        PEDAGOG√çA:
        - Incluimos "relevancia LLM" para diferenciar de vector search
        - El usuario puede saber qu√© m√©todo se us√≥
        """
        proc_code = metadata.get("procedure_code", "UNKNOWN")
        category = metadata.get("category", "general")
        score_pct = int(score * 100)

        return f"[Doc: {proc_code} ({category}), relevancia LLM: {score_pct}%]"

    # ========================================================================
    # VERSION 2.0: RETRIEVAL CON √çNDICES JSON (3 FASES)
    # ========================================================================

    def _load_all_indices(self, indices_dir: str = "data/indices") -> Dict[str, Dict]:
        """
        Carga todos los √≠ndices JSON disponibles.

        PEDAGOG√çA:
        - Los √≠ndices son archivos JSON peque√±os (res√∫menes de documentos)
        - El LLM puede leer TODOS los √≠ndices r√°pidamente
        - Decide qu√© documentos son relevantes sin leer contenido completo

        Args:
            indices_dir: Directorio con archivos index-*.json

        Returns:
            Dict {document_id: index_data}
        """
        indices_path = Path(indices_dir)

        if not indices_path.exists():
            print(f"‚ö†Ô∏è  Directorio de √≠ndices no existe: {indices_dir}")
            print("üí° Fallback: Se usar√° el m√©todo de retrieval sin √≠ndices")
            return {}

        indices = {}

        for index_file in indices_path.glob("index-*.json"):
            try:
                with open(index_file, 'r', encoding='utf-8') as f:
                    index_data = json.load(f)
                    doc_id = index_data.get("document_id", index_file.stem)
                    indices[doc_id] = index_data
            except Exception as e:
                print(f"‚ö†Ô∏è  Error cargando √≠ndice {index_file.name}: {e}")
                continue

        return indices

    async def _filter_relevant_documents(
        self,
        query: str,
        indices: Dict[str, Dict]
    ) -> List[Dict[str, Any]]:
        """
        FASE 1: LLM decide qu√© documentos son relevantes leyendo √≠ndices.

        PEDAGOG√çA:
        - El LLM lee TODOS los √≠ndices (son res√∫menes cortos)
        - Decide cu√°les son relevantes para la query
        - M√°s eficiente que leer documentos completos

        Args:
            query: Consulta del usuario
            indices: Dict con todos los √≠ndices cargados

        Returns:
            Lista de documentos relevantes con reasoning
        """
        if not indices:
            return []

        # Formatear √≠ndices para el prompt
        indices_summary = []
        for doc_id, index_data in indices.items():
            summary = f"""
Documento: {doc_id}
C√≥digo: {index_data.get('procedure_code', 'N/A')}
T√≠tulo: {index_data.get('procedure_name', 'Sin t√≠tulo')}
Categor√≠a: {index_data.get('category', 'general')}
Resumen: {index_data.get('summary', 'Sin resumen')}
N√∫mero de secciones: {len(index_data.get('sections', []))}
"""
            indices_summary.append(summary.strip())

        # Prompt para Fase 1
        prompt = f"""Tienes estos documentos disponibles (√≠ndices):

{chr(10).join(indices_summary)}

Pregunta del usuario: {query}

¬øQu√© documentos son RELEVANTES para responder esta pregunta?

Responde SOLO con un JSON v√°lido (sin markdown, sin explicaciones adicionales):
{{
  "relevant_documents": ["doc_id_1", "doc_id_2", ...],
  "reasoning": "Explicaci√≥n breve de por qu√© estos documentos son relevantes"
}}

Si ning√∫n documento es relevante, devuelve un array vac√≠o.
"""

        # Llamar al LLM (usando el chunk_evaluator como proxy al model provider)
        try:
            response = await self.chunk_evaluator.model_provider.generate(
                messages=[{"role": "user", "content": prompt}],
                temperature=0.3,
                max_tokens=500
            )

            # Parse JSON response
            response_text = response.content.strip()

            # Limpiar markdown si est√° presente
            if response_text.startswith("```json"):
                response_text = response_text.split("```json")[1].split("```")[0].strip()
            elif response_text.startswith("```"):
                response_text = response_text.split("```")[1].split("```")[0].strip()

            result = json.loads(response_text)

            # Construir lista de documentos relevantes con metadata
            relevant_docs = []
            for doc_id in result.get("relevant_documents", []):
                if doc_id in indices:
                    relevant_docs.append({
                        "document_id": doc_id,
                        "index": indices[doc_id],
                        "reasoning": result.get("reasoning", "")
                    })

            return relevant_docs

        except json.JSONDecodeError as e:
            print(f"‚ö†Ô∏è  Error parseando JSON en Fase 1: {e}")
            print(f"Respuesta del LLM: {response_text[:200]}...")
            return []
        except Exception as e:
            print(f"‚ö†Ô∏è  Error en Fase 1 (filtrar documentos): {e}")
            return []

    async def _filter_relevant_sections(
        self,
        query: str,
        document_index: Dict[str, Any]
    ) -> List[str]:
        """
        FASE 2: LLM decide qu√© secciones de un documento son relevantes.

        PEDAGOG√çA:
        - Ya sabemos que el documento es relevante (Fase 1)
        - Ahora el LLM lee el √≠ndice de secciones
        - Decide qu√© secciones espec√≠ficas leer (no todo el documento)

        Args:
            query: Consulta del usuario
            document_index: √çndice completo del documento

        Returns:
            Lista de section_ids relevantes
        """
        sections = document_index.get("sections", [])

        if not sections:
            return []

        # Formatear secciones para el prompt
        sections_summary = []
        for section in sections:
            summary = f"""
Secci√≥n {section['section_id']}: {section['title']}
P√°ginas: {section.get('page_start', '?')}-{section.get('page_end', '?')}
Resumen: {section.get('summary', 'Sin resumen')}
"""
            sections_summary.append(summary.strip())

        # Prompt para Fase 2
        prompt = f"""Documento: {document_index.get('procedure_name', 'Sin t√≠tulo')}
C√≥digo: {document_index.get('procedure_code', 'N/A')}

√çndice de secciones:
{chr(10).join(sections_summary)}

Pregunta del usuario: {query}

¬øQu√© secciones necesitas leer para responder esta pregunta?

Responde SOLO con un JSON v√°lido (sin markdown, sin explicaciones adicionales):
{{
  "relevant_sections": ["1", "5", "9"],
  "reasoning": "Explicaci√≥n breve de por qu√© estas secciones"
}}

Selecciona SOLO las secciones estrictamente necesarias (m√°ximo 3-5).
Si no est√°s seguro, es mejor incluir una secci√≥n de m√°s que omitirla.
"""

        try:
            response = await self.chunk_evaluator.model_provider.generate(
                messages=[{"role": "user", "content": prompt}],
                temperature=0.3,
                max_tokens=400
            )

            response_text = response.content.strip()

            # Limpiar markdown si est√° presente
            if response_text.startswith("```json"):
                response_text = response_text.split("```json")[1].split("```")[0].strip()
            elif response_text.startswith("```"):
                response_text = response_text.split("```")[1].split("```")[0].strip()

            result = json.loads(response_text)

            return result.get("relevant_sections", [])

        except json.JSONDecodeError as e:
            print(f"‚ö†Ô∏è  Error parseando JSON en Fase 2: {e}")
            print(f"Respuesta del LLM: {response_text[:200]}...")
            # Fallback: retornar todas las secciones
            return [s["section_id"] for s in sections]
        except Exception as e:
            print(f"‚ö†Ô∏è  Error en Fase 2 (filtrar secciones): {e}")
            # Fallback: retornar todas las secciones
            return [s["section_id"] for s in sections]

    def _load_section_content(
        self,
        document_index: Dict[str, Any],
        section_ids: List[str]
    ) -> List[Dict[str, Any]]:
        """
        FASE 3: Carga contenido SOLO de las secciones relevantes por P√ÅGINAS.

        PEDAGOG√çA:
        - Para PDFs: Lee SOLO las p√°ginas especificadas (eficiente)
        - Para Markdown: Lee documento completo y extrae por t√≠tulos
        - Mucho m√°s r√°pido y preciso que leer documento completo

        Args:
            document_index: √çndice del documento
            section_ids: IDs de secciones a cargar

        Returns:
            Lista de secciones con contenido completo
        """
        doc_path = Path(document_index.get("path", ""))

        if not doc_path.exists():
            print(f"‚ö†Ô∏è  Documento no existe: {doc_path}")
            return []

        # Extraer secciones relevantes
        sections_content = []
        all_sections = document_index.get("sections", [])
        is_pdf = doc_path.suffix.lower() == '.pdf'

        for section in all_sections:
            if section["section_id"] not in section_ids:
                continue

            try:
                # Extraer rango de p√°ginas del formato del √≠ndice
                page_start = None
                page_end = None

                # Formato 1: Array de p√°ginas ["pages": [1,2,3,4,5]]
                if section.get("pages") and isinstance(section["pages"], list):
                    page_start = min(section["pages"])
                    page_end = max(section["pages"])
                # Formato 2: String de rango ["page_range": "1-5"]
                elif section.get("page_range"):
                    try:
                        parts = section["page_range"].split("-")
                        page_start = int(parts[0])
                        page_end = int(parts[1])
                    except (ValueError, IndexError):
                        pass
                # Formato 3: Campos separados (legacy)
                elif section.get("page_start") and section.get("page_end"):
                    page_start = section["page_start"]
                    page_end = section["page_end"]

                # NUEVO: Para PDFs, leer solo p√°ginas espec√≠ficas
                if is_pdf and page_start and page_end:
                    section_content = self.document_reader.read_pdf_pages(
                        doc_path,
                        page_start,
                        page_end
                    )
                else:
                    # Fallback para Markdown o secciones sin p√°ginas
                    content = self.document_reader._read_file(doc_path)
                    section_content = self._extract_section_from_content(
                        content,
                        section
                    )

                sections_content.append({
                    "section_id": section["section_id"],
                    "title": section["title"],
                    "content": section_content,
                    "metadata": {
                        "document_id": document_index.get("document_id"),
                        "procedure_code": document_index.get("procedure_code"),
                        "procedure_name": document_index.get("procedure_name"),
                        "page_start": page_start,
                        "page_end": page_end,
                        "category": document_index.get("category")
                    }
                })

            except Exception as e:
                print(f"‚ö†Ô∏è  Error cargando secci√≥n {section['section_id']} de {doc_path.name}: {e}")
                continue

        return sections_content

    def _extract_section_from_content(
        self,
        full_content: str,
        section: Dict[str, Any]
    ) -> str:
        """
        Extrae el contenido de una secci√≥n espec√≠fica del documento completo.

        PEDAGOG√çA:
        - Busca la secci√≥n por t√≠tulo (## T√çTULO)
        - Extrae hasta la siguiente secci√≥n del mismo nivel
        - Si no encuentra, retorna una porci√≥n aproximada

        Args:
            full_content: Contenido completo del documento
            section: Dict con info de la secci√≥n

        Returns:
            Contenido de la secci√≥n
        """
        title = section.get("title", "")

        if not title:
            return ""

        # Buscar por t√≠tulo markdown (## T√çTULO)
        import re

        # Intentar encontrar la secci√≥n por t√≠tulo
        pattern = rf"^##\s+{re.escape(title)}.*?(?=^##\s+|\Z)"
        match = re.search(pattern, full_content, re.MULTILINE | re.DOTALL)

        if match:
            return match.group(0).strip()

        # Fallback: buscar t√≠tulo sin formato espec√≠fico
        lines = full_content.split("\n")
        start_idx = None

        for i, line in enumerate(lines):
            if title.lower() in line.lower():
                start_idx = i
                break

        if start_idx is not None:
            # Tomar hasta la pr√≥xima secci√≥n (t√≠tulo con ##)
            end_idx = len(lines)
            for i in range(start_idx + 1, len(lines)):
                if lines[i].strip().startswith("##"):
                    end_idx = i
                    break

            return "\n".join(lines[start_idx:end_idx]).strip()

        # √öltimo fallback: retornar resumen de la secci√≥n si existe
        return section.get("summary", f"[Contenido de secci√≥n {section['section_id']} no encontrado]")

    async def _generate_response_with_sections(
        self,
        query: str,
        sections_content: List[Dict[str, Any]]
    ) -> Dict[str, Any]:
        """
        FASE 3 (final): Genera respuesta usando secciones espec√≠ficas.

        PEDAGOG√çA:
        - El LLM lee SOLO las secciones relevantes (no documentos completos)
        - Genera respuesta citando las fuentes correctamente
        - Incluye metadata de qu√© secciones consult√≥

        Args:
            query: Consulta del usuario
            sections_content: Lista de secciones con contenido

        Returns:
            Dict con respuesta y citas
        """
        if not sections_content:
            return {
                "chunks": [],
                "method": "agent_rag_indexed",
                "message": "No se encontraron secciones relevantes"
            }

        # Formatear secciones para el prompt
        formatted_sections = []
        for section in sections_content:
            formatted = f"""
[{section['metadata']['procedure_code']} - {section['title']}, p√°ginas {section['metadata']['page_start']}-{section['metadata']['page_end']}]

{section['content']}
"""
            formatted_sections.append(formatted.strip())

        # Prompt para generar respuesta
        prompt = f"""Pregunta del usuario: {query}

Contenido relevante de los documentos AFP:

{chr(10).join(formatted_sections)}

Genera una respuesta clara y concisa que:
1. Responda directamente la pregunta
2. Use informaci√≥n SOLO del contenido proporcionado
3. Incluya citas en formato: [PROC-XXX-NNN - T√≠tulo Secci√≥n, p√°ginas X-Y]
4. Sea precisa y profesional

Respuesta:"""

        try:
            response = await self.chunk_evaluator.model_provider.generate(
                messages=[{"role": "user", "content": prompt}],
                temperature=0.5,
                max_tokens=1000
            )

            # Formatear como chunks para compatibilidad con API existente
            chunks = []
            for section in sections_content:
                citation = f"[{section['metadata']['procedure_code']} - {section['title']}, p√°ginas {section['metadata']['page_start']}-{section['metadata']['page_end']}]"

                chunks.append({
                    "content": section['content'],
                    "metadata": section['metadata'],
                    "score": 1.0,  # Score fijo, LLM ya filtr√≥
                    "reasoning": f"Secci√≥n relevante: {section['title']}",
                    "citation": citation
                })

            return {
                "response": response.content,
                "chunks": chunks,
                "method": "agent_rag_indexed",
                "sections_consulted": [
                    f"{s['metadata']['procedure_code']}: {s['title']}"
                    for s in sections_content
                ]
            }

        except Exception as e:
            print(f"‚ö†Ô∏è  Error generando respuesta final: {e}")
            return {
                "chunks": [],
                "method": "agent_rag_indexed",
                "error": str(e)
            }

    async def retrieve_with_index(
        self,
        query: str,
        indices_dir: str = "data/indices",
        documents_path: str = "data/documentos"
    ) -> Dict[str, Any]:
        """
        Retrieval en 3 FASES usando √≠ndices JSON.

        PEDAGOG√çA:
        - FASE 1: LLM lee TODOS los √≠ndices ‚Üí decide qu√© docs son relevantes
        - FASE 2: LLM lee √≠ndices de secciones ‚Üí decide qu√© secciones leer
        - FASE 3: Lee SOLO secciones espec√≠ficas ‚Üí genera respuesta

        VENTAJAS:
        - M√°s eficiente: Lee solo lo necesario
        - M√°s r√°pido: Menos texto para el LLM
        - M√°s barato: Menos tokens
        - Mejor rendimiento: Informaci√≥n m√°s precisa

        FLOW:
        Usuario: "¬øC√≥mo jubilarme anticipadamente?"
            ‚Üì
        Fase 1: Lee √≠ndices ‚Üí "PROC-JUB-002 es relevante"
            ‚Üì
        Fase 2: Lee √≠ndice PROC-JUB-002 ‚Üí "Necesito secciones 2, 5, 9"
            ‚Üì
        Fase 3: Lee secciones espec√≠ficas ‚Üí Genera respuesta con citas

        Args:
            query: Consulta del usuario
            indices_dir: Directorio con √≠ndices JSON
            documents_path: Directorio con documentos originales

        Returns:
            Dict con respuesta, chunks y metadata
        """
        start_time = time.time()

        print(f"üîç Iniciando retrieval con √≠ndices...")
        print(f"üìù Query: {query}")

        # FASE 1: Cargar √≠ndices y filtrar documentos relevantes
        print(f"\nüìö FASE 1: Filtrando documentos relevantes...")
        indices = self._load_all_indices(indices_dir)

        if not indices:
            print("‚ö†Ô∏è  No hay √≠ndices disponibles. Usando m√©todo sin √≠ndices.")
            return await self.retrieve(query, k=5, documents_path=documents_path)

        print(f"   √çndices cargados: {len(indices)}")

        relevant_docs = await self._filter_relevant_documents(query, indices)

        if not relevant_docs:
            print("‚ùå No se encontraron documentos relevantes")
            return {
                "chunks": [],
                "method": "agent_rag_indexed",
                "message": "No se encontraron documentos relevantes para tu consulta"
            }

        print(f"   ‚úÖ Documentos relevantes: {[d['document_id'] for d in relevant_docs]}")

        # FASE 2: Para cada documento, filtrar secciones relevantes
        print(f"\nüìÑ FASE 2: Filtrando secciones relevantes...")
        all_sections = []

        for doc in relevant_docs:
            doc_index = doc["index"]
            section_ids = await self._filter_relevant_sections(query, doc_index)

            if section_ids:
                print(f"   {doc['document_id']}: secciones {', '.join(section_ids)}")

                # FASE 3: Cargar contenido de secciones
                sections_content = self._load_section_content(doc_index, section_ids)
                all_sections.extend(sections_content)

        print(f"   ‚úÖ Total secciones a leer: {len(all_sections)}")

        # FASE 3 (final): Generar respuesta con secciones
        print(f"\nüí¨ FASE 3: Generando respuesta final...")
        result = await self._generate_response_with_sections(query, all_sections)

        elapsed = int((time.time() - start_time) * 1000)
        print(f"\n‚è±Ô∏è  Tiempo total: {elapsed}ms")
        print(f"‚úÖ Retrieval completado")

        result["elapsed_ms"] = elapsed
        return result

    async def retrieve_old(
        self,
        query: str,
        k: int = 5,
        documents_path: str = "data/documentos"
    ) -> Dict[str, Any]:
        """
        M√âTODO ANTIGUO: Retrieval sin √≠ndices (lee documentos completos).

        PEDAGOG√çA:
        - Mantiene compatibilidad con c√≥digo existente
        - √ötil para comparar rendimiento vs m√©todo con √≠ndices
        - Fallback si √≠ndices no existen

        Args:
            query: Consulta del usuario
            k: N√∫mero de documentos a retornar
            documents_path: Ruta a documentos

        Returns:
            Dict con chunks y reasoning del LLM
        """
        print("‚ö†Ô∏è  Usando m√©todo SIN √≠ndices (menos eficiente)")
        return await self.retrieve(query, k, documents_path)
